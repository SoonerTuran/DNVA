{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SoonerTuran/DNVA/blob/main/DNVA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HHTQmlFe7lWD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l-R76_tkAevP"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RtIaVK7U7aG9"
      },
      "outputs": [],
      "source": [
        "class ALU(nn.Module):\n",
        "    def __init__(self, input_size, opcode_size, output_size, flag_size, hidden_size=32):\n",
        "        super(ALU, self).__init__()\n",
        "\n",
        "        self.input_size = input_size\n",
        "        self.opcode_size = opcode_size\n",
        "        self.output_size = output_size\n",
        "        self.flag_size = flag_size\n",
        "\n",
        "        # Layers definition\n",
        "        self.linear1 = nn.Linear(self.input_size + self.opcode_size, hidden_size)\n",
        "        self.linear2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.linear3 = nn.Linear(hidden_size, self.output_size + flag_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.sin(self.linear1(x))\n",
        "        x = torch.sin(self.linear2(x))\n",
        "        x = torch.sin(self.linear3(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e2q6ivozzc1G"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        # Giriş boyutu input_size olarak alınır.\n",
        "        # Çıkış boyutu ise 2^input_size olarak belirlenir.\n",
        "        output_size = 2 ** input_size\n",
        "\n",
        "        # 5 katmanlı bir fully connected (dense) ağ tanımlanıyor.\n",
        "        self.fc1 = nn.Linear(input_size, input_size*2)\n",
        "        self.fc2 = nn.Linear(input_size*2, input_size*3)\n",
        "        self.fc3 = nn.Linear(input_size*3, input_size*4)\n",
        "        self.fc4 = nn.Linear(input_size*4, input_size*4)\n",
        "        self.fc5 = nn.Linear(input_size*4, output_size)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = torch.sin(self.fc1(x))\n",
        "      x = torch.sin(self.fc2(x))\n",
        "      x = torch.sin(self.fc3(x))\n",
        "      x = torch.sin(self.fc4(x))\n",
        "      x = torch.softmax(self.fc5(x), dim=1)\n",
        "      return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d_V5RyHV_Pdo"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import itertools\n",
        "\n",
        "input_size = 10\n",
        "num_samples = 2 ** input_size\n",
        "output_size = 2 ** input_size\n",
        "\n",
        "# Tüm olası ikili sayıları oluşturmak için itertools.product kullanılıyor.\n",
        "binary_values = list(itertools.product([0, 1], repeat=input_size))\n",
        "# Toplam ikili sayı sayısı num_samples'tan fazla ise, sadece ilk num_samples kadarını alırız.\n",
        "binary_values = binary_values[:num_samples]\n",
        "\n",
        "# Liste halindeki ikili sayıları tensörlere dönüştürme\n",
        "train_inputs = torch.tensor(binary_values, dtype=torch.int, device=device , requires_grad=False)\n",
        "test_inputs = torch.randint(0, 2, (num_samples, input_size), device=device, requires_grad=False)\n",
        "\n",
        "# One-hot çıktıları oluşturma\n",
        "train_outputs = torch.zeros(num_samples, output_size, device=device)\n",
        "test_outputs = torch.zeros(num_samples, output_size, device=device)\n",
        "for i in range(num_samples):\n",
        "    # Her ikili sayıyı ondalık olarak dönüştürme\n",
        "    decimal1 = int(''.join(map(str, train_inputs[i].tolist())), 2)\n",
        "    decimal2 = int(''.join(map(str, test_inputs[i].tolist())), 2)\n",
        "    # Karşılık gelen indekse 1 atama\n",
        "    train_outputs[i][decimal1] = 1\n",
        "    test_outputs[i][decimal2] = 1\n",
        "\n",
        "train_inputs = train_inputs.float()\n",
        "test_inputs = test_inputs.float()\n",
        "train_outputs = train_outputs.float()\n",
        "test_outputs = test_outputs.float()\n",
        "\n",
        "del binary_values\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4LfP6Vi074az"
      },
      "outputs": [],
      "source": [
        "model = Decoder(input_size=input_size)\n",
        "model.to(device)\n",
        "\n",
        "# Setup a loss function\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# Setup an optimizer (stochastic gradient descent)\n",
        "optimizer = torch.optim.Adam(params = model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "id": "GmP6wpIw9XgQ",
        "outputId": "6072a610-5032-45d6-b3a7-cd396ac03f30"
      },
      "outputs": [],
      "source": [
        "def calculate_accuracy(y_pred, y_true):\n",
        "    _, predicted = torch.max(y_pred.data, 1)\n",
        "    correct = (predicted == torch.argmax(y_true, 1)).sum().item()\n",
        "    accuracy = correct / y_true.size(0)\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "epochs = 20000\n",
        "\n",
        "# Track different values\n",
        "epoch_count = []\n",
        "loss_values = []\n",
        "test_loss_values = []\n",
        "accuracy_values = []\n",
        "test_accuracy_values = []\n",
        "\n",
        "#Training\n",
        "for epoch in range(epochs):\n",
        "  # Set the model to training mode\n",
        "  model.train() # train mode in PyTorch sets all parameters that require gradients to require gradients\n",
        "\n",
        "  # 1. Forward pass\n",
        "  y_pred = model(train_inputs)\n",
        "\n",
        "  # 2. Calculate the loss\n",
        "  loss = loss_fn(y_pred, train_outputs)\n",
        "\n",
        "  # 3. Optimizer zero grad\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  # 4. Perform backpropagation on the loss with respect to the parameters of the model (calculate gradients of each parameter)\n",
        "  loss.backward()\n",
        "\n",
        "  # 5. Step the optimizer (perform gradient descent)\n",
        "  optimizer.step() # by default how the optimizer changes will acculumate through the loop so... we have to zero them above in step 3 for the next iteration of the loop\n",
        "\n",
        "  # Calculate training accuracy\n",
        "  accuracy = calculate_accuracy(y_pred, train_outputs)\n",
        "\n",
        "  ### Testing\n",
        "  model.eval() # turns off different settings in the model not needed for evaluation/testing (dropout/batch norm layers)\n",
        "  with torch.inference_mode(): # turns off gradient tracking & a couple more things behind the scenes\n",
        "    # 1. Do the forward pass\n",
        "    test_pred = model(test_inputs)\n",
        "\n",
        "    # 2. Calculate the loss\n",
        "    test_loss = loss_fn(test_pred, test_outputs)\n",
        "\n",
        "    # Calculate testing accuracy\n",
        "    test_accuracy = calculate_accuracy(test_pred, test_outputs)\n",
        "\n",
        "  # Print out what's happenin'\n",
        "  if epoch % 100  == 0:\n",
        "    epoch_count.append(epoch)\n",
        "    loss_values.append(loss.detach().item())\n",
        "    test_loss_values.append(test_loss.detach().item())\n",
        "\n",
        "    accuracy_values.append(accuracy)\n",
        "    test_accuracy_values.append(test_accuracy)\n",
        "\n",
        "    print(f\"Epoch: {epoch} | Loss: {loss.detach().item():.6f} | Test loss: {test_loss.detach().item():.6f} | Train Accuracy: {accuracy:.6f} | Test Accuracy: {test_accuracy:.6f}\")\n",
        "\n",
        "  del loss, test_loss, y_pred\n",
        "  torch.cuda.empty_cache()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_rNTkPzO_e3V"
      },
      "outputs": [],
      "source": [
        "# Plot the loss curves\n",
        "plt.plot(epoch_count, np.array(torch.tensor(loss_values)), label=\"Train loss\")\n",
        "plt.plot(epoch_count, np.array(torch.tensor(test_loss_values)), label=\"Test loss\")\n",
        "plt.title(\"Training and test loss curves\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot the loss curves\n",
        "plt.plot(epoch_count, np.array(torch.tensor(accuracy_values)), label=\"Train Acc\")\n",
        "plt.plot(epoch_count, np.array(torch.tensor(test_loss_values)), label=\"Test Acc\")\n",
        "plt.title(\"Training and test acc curves\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jopNuH_Pc0wZ"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "with torch.inference_mode():\n",
        "  test_pred = model(test_inputs)\n",
        "\n",
        "index = torch.randint(low=0, high=512, size=(1,1))[0][0]\n",
        "print(test_inputs[index])\n",
        "\n",
        "print(test_pred[index].round(decimals=2))\n",
        "print(test_pred[index].round(decimals=2).argmax())\n",
        "\n",
        "# Binary tensoru bir stringe dönüştürelim\n",
        "binary_str = ''.join([str(int(i)) for i in test_inputs[index]])\n",
        "\n",
        "# Binary stringi desimal sayıya dönüştürelim\n",
        "decimal_number = int(binary_str, 2)\n",
        "print(decimal_number)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyOm8ntF/X0YhDJkG3mPd093",
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
