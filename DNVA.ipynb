{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SoonerTuran/DNVA/blob/main/DNVA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "HHTQmlFe7lWD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "l-R76_tkAevP"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "RtIaVK7U7aG9"
      },
      "outputs": [],
      "source": [
        "class ALU(nn.Module):\n",
        "    def __init__(self, input_size, opcode_size, output_size, flag_size, hidden_size=32):\n",
        "        super(ALU, self).__init__()\n",
        "\n",
        "        # Layers definition\n",
        "        self.linear1 = nn.Linear(self.input_size + self.opcode_size, hidden_size)\n",
        "        self.linear2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.linear3 = nn.Linear(hidden_size, self.output_size + flag_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.sin(self.linear1(x))\n",
        "        x = torch.sin(self.linear2(x))\n",
        "        x = torch.sin(self.linear3(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "e2q6ivozzc1G"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        output_size = 2 ** input_size\n",
        "        self.fc1 = nn.Linear(input_size, input_size*2)\n",
        "        self.fc2 = nn.Linear(input_size*2, input_size*3)\n",
        "        self.fc3 = nn.Linear(input_size*3, input_size*4)\n",
        "        self.fc4 = nn.Linear(input_size*4, input_size*5)\n",
        "        self.fc5 = nn.Linear(input_size*5, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = torch.sin(self.fc1(x))\n",
        "      x = torch.sin(self.fc2(x))\n",
        "      x = torch.sin(self.fc3(x))\n",
        "      x = torch.sin(self.fc4(x))\n",
        "      x = torch.softmax(self.fc5(x), dim=1)\n",
        "      return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "k3FNlCLtPlOl"
      },
      "outputs": [],
      "source": [
        "class RAM(nn.Module):\n",
        "    def __init__(self, address_size, data_size):\n",
        "        super(RAM, self).__init__()\n",
        "\n",
        "        self.address_size = address_size\n",
        "        self.data_size = data_size\n",
        "        self.decoder = Decoder(address_size)\n",
        "\n",
        "        # initialize a memory block\n",
        "        self.memory = torch.randn(2**address_size, data_size)\n",
        "\n",
        "    def forward(self, address, data, write):\n",
        "        # address should be in one-hot representation\n",
        "        one_hot_address = self.decoder(address)\n",
        "\n",
        "        write = write.view(-1, 1)\n",
        "\n",
        "        read_data = torch.matmul(one_hot_address, self.memory) * (1 - write)\n",
        "\n",
        "        self.memory = (self.memory * (1 - one_hot_address.unsqueeze(-1) * write)) + data * one_hot_address.unsqueeze(-1) * write\n",
        "\n",
        "        return read_data + data * write"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36XOR8tcUDyu",
        "outputId": "aaf097c5-5249-4791-a3bf-3a4df68c4d95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Data:  tensor([[0.9350, 0.6063]])\n",
            "Test Address:  tensor([[0., 0.]])\n",
            "Memory:  tensor([[ 0.0795, -0.0887],\n",
            "        [ 0.0410, -0.3014],\n",
            "        [-1.2327, -0.4292],\n",
            "        [ 1.2684, -0.6368]])\n",
            "tensor([[4.1879e-29, 5.1141e-13, 1.0000e+00, 1.5383e-25]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "Memory after write:  tensor([[[ 0.0795, -0.0887],\n",
            "         [ 0.0410, -0.3014],\n",
            "         [-0.1489,  0.0885],\n",
            "         [ 1.2684, -0.6368]]], grad_fn=<AddBackward0>)\n",
            "tensor([[4.1879e-29, 5.1141e-13, 1.0000e+00, 1.5383e-25]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "Memory after read:  tensor([[[ 0.0795, -0.0887],\n",
            "         [ 0.0410, -0.3014],\n",
            "         [ 0.3931,  0.3474],\n",
            "         [ 1.2684, -0.6368]]], grad_fn=<AddBackward0>)\n",
            "Written data:  tensor([[0.9350, 0.6063]])\n",
            "Read data:  tensor([[[0.3931, 0.3474]]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ],
      "source": [
        "def test_RAM():\n",
        "    # Create a RAM instance with 2 bit address and 2 bit data\n",
        "    address_size = 2\n",
        "    data_size = 2\n",
        "    ram = RAM(address_size, data_size)\n",
        "\n",
        "    # Create some test data to write to the RAM\n",
        "    test_data = torch.rand((1, data_size))\n",
        "    print(\"Test Data: \", test_data)\n",
        "\n",
        "    # Create a test address to write to/read from\n",
        "    test_address = torch.randint(0, 2, (1, address_size))\n",
        "    test_address = test_address.float()\n",
        "    print(\"Test Address: \", test_address)\n",
        "\n",
        "    print(\"Memory: \", ram.memory)\n",
        "    # Write operation\n",
        "    write_flag = torch.tensor([1.])  # write = 1\n",
        "    ram(test_address, test_data, write_flag)\n",
        "    print(\"Memory after write: \", ram.memory)\n",
        "\n",
        "    # Read operation\n",
        "    write_flag = torch.tensor([0.])  # write = 0\n",
        "    read_data = ram(test_address, test_data, write_flag)\n",
        "    print(\"Memory after read: \", ram.memory)\n",
        "\n",
        "    print(\"Written data: \", test_data)\n",
        "    print(\"Read data: \", read_data)\n",
        "\n",
        "# Run the test\n",
        "test_RAM()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "d_V5RyHV_Pdo"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "\n",
        "input_size = 13\n",
        "num_samples = 2 ** input_size\n",
        "output_size = 2 ** input_size\n",
        "\n",
        "# Tüm olası ikili sayıları oluşturmak için itertools.product kullanılıyor.\n",
        "binary_values = list(itertools.product([0, 1], repeat=input_size))\n",
        "# Toplam ikili sayı sayısı num_samples'tan fazla ise, sadece ilk num_samples kadarını alırız.\n",
        "binary_values = binary_values[:num_samples]\n",
        "\n",
        "# Liste halindeki ikili sayıları tensörlere dönüştürme\n",
        "train_inputs = torch.tensor(binary_values, dtype=torch.int, device=device , requires_grad=False)\n",
        "test_inputs = torch.randint(0, 2, (num_samples, input_size), device=device, requires_grad=False)\n",
        "\n",
        "# One-hot çıktıları oluşturma\n",
        "train_outputs = torch.zeros(num_samples, output_size, device=device)\n",
        "test_outputs = torch.zeros(num_samples, output_size, device=device)\n",
        "for i in range(num_samples):\n",
        "    # Her ikili sayıyı ondalık olarak dönüştürme\n",
        "    decimal1 = int(''.join(map(str, train_inputs[i].tolist())), 2)\n",
        "    decimal2 = int(''.join(map(str, test_inputs[i].tolist())), 2)\n",
        "    # Karşılık gelen indekse 1 atama\n",
        "    train_outputs[i][decimal1] = 1\n",
        "    test_outputs[i][decimal2] = 1\n",
        "\n",
        "train_inputs = train_inputs.float()\n",
        "test_inputs = test_inputs.float()\n",
        "train_outputs = train_outputs.float()\n",
        "test_outputs = test_outputs.float()\n",
        "\n",
        "del binary_values\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "4LfP6Vi074az"
      },
      "outputs": [],
      "source": [
        "model = Decoder(input_size=input_size)\n",
        "model.to(device)\n",
        "\n",
        "# Setup a loss function\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# Setup an optimizer (stochastic gradient descent)\n",
        "optimizer = torch.optim.Adam(params = model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GmP6wpIw9XgQ",
        "outputId": "16ece41d-865f-4120-a25c-d22af189f731"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1.0611e-04, 1.1090e-04, 1.0229e-04,  ..., 1.1024e-04, 1.1210e-04,\n",
            "         1.1799e-04],\n",
            "        [1.0767e-04, 1.1254e-04, 1.0015e-04,  ..., 1.0859e-04, 1.0977e-04,\n",
            "         1.1893e-04],\n",
            "        [1.0411e-04, 1.0943e-04, 1.0289e-04,  ..., 1.0749e-04, 1.1221e-04,\n",
            "         1.1306e-04],\n",
            "        ...,\n",
            "        [9.5136e-05, 1.0003e-04, 1.0913e-04,  ..., 1.0929e-04, 1.1410e-04,\n",
            "         1.1469e-04],\n",
            "        [9.4526e-05, 9.8809e-05, 1.0997e-04,  ..., 1.0852e-04, 1.1533e-04,\n",
            "         1.1166e-04],\n",
            "        [9.4059e-05, 9.9667e-05, 1.0825e-04,  ..., 1.0810e-04, 1.1391e-04,\n",
            "         1.1198e-04]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[9.1245e-05, 9.7906e-05, 1.1107e-04,  ..., 1.1003e-04, 1.1492e-04,\n",
            "         1.1283e-04],\n",
            "        [9.0577e-05, 9.8757e-05, 1.0886e-04,  ..., 1.1045e-04, 1.1229e-04,\n",
            "         1.0706e-04],\n",
            "        [9.7870e-05, 1.0344e-04, 1.0586e-04,  ..., 1.0747e-04, 1.1271e-04,\n",
            "         1.0580e-04],\n",
            "        ...,\n",
            "        [9.5003e-05, 9.9080e-05, 1.0888e-04,  ..., 1.0753e-04, 1.1426e-04,\n",
            "         1.0979e-04],\n",
            "        [9.4362e-05, 1.0186e-04, 1.1033e-04,  ..., 1.0936e-04, 1.1412e-04,\n",
            "         1.1399e-04],\n",
            "        [1.0229e-04, 1.0497e-04, 1.0934e-04,  ..., 1.1294e-04, 1.1333e-04,\n",
            "         1.2134e-04]])\n",
            "Epoch: 0 | Loss: 9.010912 | Test loss: 9.010911 | Train Accuracy: 0.000122 | Test Accuracy: 0.000122\n",
            "tensor([[1.0601e-04, 1.1093e-04, 1.0226e-04,  ..., 1.1031e-04, 1.1214e-04,\n",
            "         1.1801e-04],\n",
            "        [1.0772e-04, 1.1260e-04, 1.0015e-04,  ..., 1.0859e-04, 1.0968e-04,\n",
            "         1.1883e-04],\n",
            "        [1.0394e-04, 1.0937e-04, 1.0304e-04,  ..., 1.0762e-04, 1.1217e-04,\n",
            "         1.1311e-04],\n",
            "        ...,\n",
            "        [9.4757e-05, 9.9896e-05, 1.0925e-04,  ..., 1.0968e-04, 1.1376e-04,\n",
            "         1.1504e-04],\n",
            "        [9.4013e-05, 9.8597e-05, 1.1021e-04,  ..., 1.0899e-04, 1.1503e-04,\n",
            "         1.1209e-04],\n",
            "        [9.3661e-05, 9.9492e-05, 1.0849e-04,  ..., 1.0851e-04, 1.1352e-04,\n",
            "         1.1232e-04]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[9.0799e-05, 9.7760e-05, 1.1116e-04,  ..., 1.1050e-04, 1.1460e-04,\n",
            "         1.1317e-04],\n",
            "        [9.0213e-05, 9.8623e-05, 1.0902e-04,  ..., 1.1079e-04, 1.1191e-04,\n",
            "         1.0730e-04],\n",
            "        [9.7558e-05, 1.0330e-04, 1.0609e-04,  ..., 1.0775e-04, 1.1241e-04,\n",
            "         1.0596e-04],\n",
            "        ...,\n",
            "        [9.4490e-05, 9.8852e-05, 1.0914e-04,  ..., 1.0793e-04, 1.1389e-04,\n",
            "         1.1015e-04],\n",
            "        [9.4008e-05, 1.0175e-04, 1.1041e-04,  ..., 1.0984e-04, 1.1385e-04,\n",
            "         1.1419e-04],\n",
            "        [1.0192e-04, 1.0488e-04, 1.0934e-04,  ..., 1.1326e-04, 1.1343e-04,\n",
            "         1.2175e-04]])\n",
            "tensor([[1.0591e-04, 1.1096e-04, 1.0223e-04,  ..., 1.1039e-04, 1.1219e-04,\n",
            "         1.1802e-04],\n",
            "        [1.0779e-04, 1.1267e-04, 1.0014e-04,  ..., 1.0859e-04, 1.0959e-04,\n",
            "         1.1874e-04],\n",
            "        [1.0377e-04, 1.0930e-04, 1.0318e-04,  ..., 1.0775e-04, 1.1213e-04,\n",
            "         1.1315e-04],\n",
            "        ...,\n",
            "        [9.4371e-05, 9.9760e-05, 1.0938e-04,  ..., 1.1008e-04, 1.1343e-04,\n",
            "         1.1539e-04],\n",
            "        [9.3491e-05, 9.8377e-05, 1.1046e-04,  ..., 1.0946e-04, 1.1474e-04,\n",
            "         1.1250e-04],\n",
            "        [9.3256e-05, 9.9311e-05, 1.0872e-04,  ..., 1.0891e-04, 1.1314e-04,\n",
            "         1.1265e-04]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[9.0341e-05, 9.7603e-05, 1.1125e-04,  ..., 1.1097e-04, 1.1428e-04,\n",
            "         1.1350e-04],\n",
            "        [8.9833e-05, 9.8480e-05, 1.0918e-04,  ..., 1.1115e-04, 1.1154e-04,\n",
            "         1.0752e-04],\n",
            "        [9.7232e-05, 1.0315e-04, 1.0632e-04,  ..., 1.0805e-04, 1.1212e-04,\n",
            "         1.0611e-04],\n",
            "        ...,\n",
            "        [9.3964e-05, 9.8614e-05, 1.0940e-04,  ..., 1.0833e-04, 1.1353e-04,\n",
            "         1.1049e-04],\n",
            "        [9.3644e-05, 1.0164e-04, 1.1049e-04,  ..., 1.1032e-04, 1.1359e-04,\n",
            "         1.1439e-04],\n",
            "        [1.0154e-04, 1.0480e-04, 1.0935e-04,  ..., 1.1358e-04, 1.1354e-04,\n",
            "         1.2217e-04]])\n",
            "tensor([[1.0581e-04, 1.1098e-04, 1.0220e-04,  ..., 1.1046e-04, 1.1223e-04,\n",
            "         1.1804e-04],\n",
            "        [1.0785e-04, 1.1274e-04, 1.0012e-04,  ..., 1.0859e-04, 1.0949e-04,\n",
            "         1.1865e-04],\n",
            "        [1.0360e-04, 1.0924e-04, 1.0331e-04,  ..., 1.0788e-04, 1.1209e-04,\n",
            "         1.1319e-04],\n",
            "        ...,\n",
            "        [9.3978e-05, 9.9617e-05, 1.0951e-04,  ..., 1.1048e-04, 1.1310e-04,\n",
            "         1.1572e-04],\n",
            "        [9.2958e-05, 9.8147e-05, 1.1071e-04,  ..., 1.0994e-04, 1.1446e-04,\n",
            "         1.1291e-04],\n",
            "        [9.2843e-05, 9.9124e-05, 1.0896e-04,  ..., 1.0932e-04, 1.1276e-04,\n",
            "         1.1296e-04]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[8.9869e-05, 9.7435e-05, 1.1134e-04,  ..., 1.1145e-04, 1.1397e-04,\n",
            "         1.1382e-04],\n",
            "        [8.9438e-05, 9.8325e-05, 1.0934e-04,  ..., 1.1150e-04, 1.1117e-04,\n",
            "         1.0773e-04],\n",
            "        [9.6892e-05, 1.0298e-04, 1.0654e-04,  ..., 1.0834e-04, 1.1183e-04,\n",
            "         1.0623e-04],\n",
            "        ...,\n",
            "        [9.3425e-05, 9.8364e-05, 1.0966e-04,  ..., 1.0874e-04, 1.1318e-04,\n",
            "         1.1082e-04],\n",
            "        [9.3270e-05, 1.0152e-04, 1.1057e-04,  ..., 1.1080e-04, 1.1333e-04,\n",
            "         1.1457e-04],\n",
            "        [1.0117e-04, 1.0471e-04, 1.0936e-04,  ..., 1.1390e-04, 1.1366e-04,\n",
            "         1.2258e-04]])\n",
            "tensor([[1.0570e-04, 1.1101e-04, 1.0217e-04,  ..., 1.1054e-04, 1.1227e-04,\n",
            "         1.1805e-04],\n",
            "        [1.0793e-04, 1.1282e-04, 1.0010e-04,  ..., 1.0858e-04, 1.0938e-04,\n",
            "         1.1856e-04],\n",
            "        [1.0342e-04, 1.0918e-04, 1.0345e-04,  ..., 1.0801e-04, 1.1206e-04,\n",
            "         1.1322e-04],\n",
            "        ...,\n",
            "        [9.3579e-05, 9.9468e-05, 1.0964e-04,  ..., 1.1088e-04, 1.1278e-04,\n",
            "         1.1605e-04],\n",
            "        [9.2416e-05, 9.7909e-05, 1.1095e-04,  ..., 1.1043e-04, 1.1419e-04,\n",
            "         1.1329e-04],\n",
            "        [9.2421e-05, 9.8931e-05, 1.0920e-04,  ..., 1.0972e-04, 1.1239e-04,\n",
            "         1.1326e-04]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[8.9383e-05, 9.7255e-05, 1.1144e-04,  ..., 1.1194e-04, 1.1367e-04,\n",
            "         1.1411e-04],\n",
            "        [8.9028e-05, 9.8160e-05, 1.0950e-04,  ..., 1.1187e-04, 1.1081e-04,\n",
            "         1.0791e-04],\n",
            "        [9.6537e-05, 1.0281e-04, 1.0676e-04,  ..., 1.0864e-04, 1.1154e-04,\n",
            "         1.0634e-04],\n",
            "        ...,\n",
            "        [9.2872e-05, 9.8103e-05, 1.0991e-04,  ..., 1.0915e-04, 1.1284e-04,\n",
            "         1.1113e-04],\n",
            "        [9.2885e-05, 1.0140e-04, 1.1064e-04,  ..., 1.1129e-04, 1.1308e-04,\n",
            "         1.1474e-04],\n",
            "        [1.0080e-04, 1.0462e-04, 1.0938e-04,  ..., 1.1422e-04, 1.1378e-04,\n",
            "         1.2300e-04]])\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-74-c7ea5804815a>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;31m# Calculate testing accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mtest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;31m# Print out what's happenin'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-74-c7ea5804815a>\u001b[0m in \u001b[0;36mcalculate_accuracy\u001b[0;34m(y_pred, y_true)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcalculate_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorrect\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "def calculate_accuracy(y_pred, y_true):\n",
        "    _, predicted = torch.max(y_pred.data, 1)\n",
        "    correct = (predicted == torch.argmax(y_true, 1)).sum().item()\n",
        "    accuracy = correct / y_true.size(0)\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "epochs = 20000\n",
        "\n",
        "# Track different values\n",
        "epoch_count = []\n",
        "loss_values = []\n",
        "test_loss_values = []\n",
        "accuracy_values = []\n",
        "test_accuracy_values = []\n",
        "\n",
        "#Training\n",
        "for epoch in range(epochs):\n",
        "  # Set the model to training mode\n",
        "  model.train() # train mode in PyTorch sets all parameters that require gradients to require gradients\n",
        "\n",
        "  # 1. Forward pass\n",
        "  y_pred = model(train_inputs)\n",
        "\n",
        "  # 2. Calculate the loss\n",
        "  loss = loss_fn(y_pred, train_outputs)\n",
        "\n",
        "  # 3. Optimizer zero grad\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  # 4. Perform backpropagation on the loss with respect to the parameters of the model (calculate gradients of each parameter)\n",
        "  loss.backward()\n",
        "\n",
        "  # 5. Step the optimizer (perform gradient descent)\n",
        "  optimizer.step() # by default how the optimizer changes will acculumate through the loop so... we have to zero them above in step 3 for the next iteration of the loop\n",
        "\n",
        "  # Calculate training accuracy\n",
        "  accuracy = calculate_accuracy(y_pred, train_outputs)\n",
        "\n",
        "  ### Testing\n",
        "  model.eval() # turns off different settings in the model not needed for evaluation/testing (dropout/batch norm layers)\n",
        "  with torch.inference_mode(): # turns off gradient tracking & a couple more things behind the scenes\n",
        "    # 1. Do the forward pass\n",
        "    test_pred = model(test_inputs)\n",
        "\n",
        "    # 2. Calculate the loss\n",
        "    test_loss = loss_fn(test_pred, test_outputs)\n",
        "\n",
        "    # Calculate testing accuracy\n",
        "    test_accuracy = calculate_accuracy(test_pred, test_outputs)\n",
        "\n",
        "  # Print out what's happenin'\n",
        "  if epoch % 100  == 0:\n",
        "    epoch_count.append(epoch)\n",
        "    loss_values.append(loss.detach().item())\n",
        "    test_loss_values.append(test_loss.detach().item())\n",
        "\n",
        "    accuracy_values.append(accuracy)\n",
        "    test_accuracy_values.append(test_accuracy)\n",
        "\n",
        "    print(f\"Epoch: {epoch} | Loss: {loss.detach().item():.6f} | Test loss: {test_loss.detach().item():.6f} | Train Accuracy: {accuracy:.6f} | Test Accuracy: {test_accuracy:.6f}\")\n",
        "\n",
        "  del loss, test_loss, y_pred\n",
        "  torch.cuda.empty_cache()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_rNTkPzO_e3V"
      },
      "outputs": [],
      "source": [
        "# Plot the loss curves\n",
        "plt.plot(epoch_count, np.array(torch.tensor(loss_values)), label=\"Train loss\")\n",
        "plt.plot(epoch_count, np.array(torch.tensor(test_loss_values)), label=\"Test loss\")\n",
        "plt.title(\"Training and test loss curves\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.legend();\n",
        "plt.show()\n",
        "\n",
        "# Plot the loss curves\n",
        "plt.plot(epoch_count, np.array(torch.tensor(accuracy_values)), label=\"Train Acc\")\n",
        "plt.plot(epoch_count, np.array(torch.tensor(test_loss_values)), label=\"Test Acc\")\n",
        "plt.title(\"Training and test acc curves\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.legend();\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jopNuH_Pc0wZ"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "with torch.inference_mode():\n",
        "  test_pred = model(test_inputs)\n",
        "\n",
        "index = torch.randint(low=0, high=512, size=(1,1))[0][0]\n",
        "print(test_inputs[index])\n",
        "\n",
        "print(test_pred[index].round(decimals=2))\n",
        "print(test_pred[index].round(decimals=2).argmax())\n",
        "\n",
        "# Binary tensoru bir stringe dönüştürelim\n",
        "binary_str = ''.join([str(int(i)) for i in test_inputs[index]])\n",
        "\n",
        "# Binary stringi desimal sayıya dönüştürelim\n",
        "decimal_number = int(binary_str, 2)\n",
        "print(decimal_number)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOi5xuKBRMztv8po8QSrUoX",
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
